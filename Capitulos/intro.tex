\chapter{Introducción y Motivación}

\section{Historia}
La detección de objetos es una de las áreas de la visión por computadora que está creciendo muy rápidamente. Gracias al aprendizaje profundo, cada año, los nuevos algoritmos/modelos siguen superando a los anteriores. Aunque la visión por computadora recientemente tomo gran importancia (el momento decisivo ocurrió en 2012 cuando AlexNet ganó ImageNet), ciertamente no es un nuevo campo científico. Uno de los artículos más influyentes en Visión Informática fue publicado por dos neurofisiólogos, David Hubel y Torsten Wiesel, en 1959. Su publicación, titulada “Receptive fields of single neurons in the cat’s striate cortex” en español ”Campos receptivos de neuronas individuales en la corteza estriada del gato", describieron las propiedades de respuesta central de las neuronas corticales visuales y cómo la experiencia visual de un gato moldea su arquitectura cortical. Los investigadores establecieron, a través de su experimentación \autoref{fig:ExpermentoHubelTorsten}, que existen neuronas simples y complejas en la corteza visual primaria y que el procesamiento visual siempre comienza con estructuras simples como los bordes orientados. En la actualidad, es esencialmente el principio básico detrás del aprendizaje profundo.\\
\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{img/cat.jpg}
	\caption{Simple explicación del experimento realizado por David Hubel y Torsten Wiesel}
	\label{fig:ExpermentoHubelTorsten}
\end{figure}

Otro echo importante en la historia de la visión por computadora fue, en 1959, Russell Kirsch y sus colegas desarrollaron un aparato que permitía transformar imágenes en cuadrículas de números que las máquinas de lenguaje binario podían entender. En la década de 1960 fue cuando la IA se convirtió en una disciplina académica y algunos de los investigadores, eran extremadamente optimistas sobre el futuro del campo. En este periodo, Seymour Papert, profesor del laboratorio de IA del MIT, decidió lanzar el Proyecto de Verano y resolver, en pocos meses, el problema de la visión artificial. Los estudiantes debían diseñar una plataforma que pudiera realizar, automáticamente, segmentación de fondo y extraer objetos no superpuestos de imágenes del mundo real. Claro esta que el proyecto no fue un éxito. Cincuenta años después, todavía no estamos cerca de resolver la visión por computadora. Sin embargo, ese proyecto fue, el nacimiento oficial de CV como campo científico. A este acontecimiento le siguieron una gran cantidad de investigaciones que hicieron grandes aportes al campo de la vision por computadoras. Como la tesis de doctorado de Roberts, Lawrence ~\cite{roberts1963machine} en 1963, el paper de David Marr~\cite{vision_marr} en 1982, entre los mas reconocidos.\\

Pero los aportes mas influyentes a este campo empezaron a surguir en los dos mil.
En 2001 Paul Viola y Michael Jones presentaron el primer detector de rostros que funcionó en tiempo real. Aunque no se basa en el aprendizaje profundo, el algoritmo tenia una relación con el mismo, ya que, al procesar imágenes, aprendió qué características podría ayudar a localizar caras, inspirados en el experimento de David Hubel y Torsten Wiesel. En 2006 comenzó la competencia de Pascal VOC, que permitió evaluar el desempeño de diferentes métodos para el reconocimiento de la clase de objeto. En 2010 siguiendo los pasos de Pascal VOC, inicio el concurso de reconocimiento visual a gran escala ImageNet (ILSVRC). En 2010 y 2011, la tasa de error del ILSVRC en la clasificación de imágenes rondaba el 26\%  Pero en 2012, un equipo de la Universidad de Toronto ingresó a la competencia un modelo de red neuronal convolucional (AlexNet) y eso cambió todo. El modelo, similar en su arquitectura al LeNet-5 de Yann LeCun, logró una tasa de error del 16,4\%. En los años siguientes, las tasas de error en la clasificación de imágenes en ILSVRC cayeron a un pequeño porcentaje, como se observa en la \autoref{fig:EvolucionILSVRC} y los ganadores, desde 2012, siempre han sido redes neuronales convolucionales.

\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{img/imgnet-grafico.png}
	\caption{Evolución de los modelos propuestos en la competencia ILSVRC}
	\label{fig:EvolucionILSVRC}
\end{figure}

\section{Detectores y ZSD}
La detección de objetos es un sub-problema de la visión artificial, que estudia cómo detectar la presencia de objetos en una imagen sobre su apariencia visual. Debido a la complejidad de poder detectar todas las instancias de todos los posibles objectos en una imagen, existen diferentes tareas que tratan de disminuir la dificultad.  Par poder explicar los distintos problemas, es necesario distinguir dos conjuntos. Los datos de entrenamiento, consta de las imágenes que se usaran para entrenar el modelo, con sus respectivas etiquetas, es decir, que objetos se encuentran en la imagen, localización de los objetos, descripción de la imagen, o cualquier información extra que requiera la tarea. Las imágenes de prueba, es el conjunto donde se observara o medirá la eficiencia del modelo ya entrenado. Supongamos que las etiquetas, solo cuenta con dos tipos de informacion, que clase de objeto es, es decir si es un perro, auto, persona, etc. y su localización en la imagen. Todas las clases que aparecen en los datos de entrenamiento llamaremos clases visibles o vistas. Toda aquella clase que no sea una clase vista la llamearemos imbisible o no vista.\\
La \textbf{clasificación}, consta en un modelo capas de retornar que objecto de las clases vistas se encuentra  en una imagen.\textbf{ Clasificación + localización}, ademas de poder clasificar tiene que ser capas de ubicar el objecto en la imagen. Ambos modelos clasifican en una sola clase vista.\textbf{ El reconocimiento de imagen}, predice que objetos perteneciente a las clases visibles están presente en la imagen. \textbf{La detección de objetos}, tiene que ser capas ademas, de poder localizar dichos objetos. El tradicional \textbf{reconocimiento por disparo cero}, tiene que poder reconocer clases no vistas. Por ultimo la \textbf{detección de objetos por disparo cero} o ZSD por sus siglas en ingles, debe localizar y clasificar todas las instancias de objetos en la imagen, sin depender si es una clase vista o no. La \autoref{fig:DetectoresYSZD} muestra un ejemplo de las distintas tareas antes mencionadas. \\
\begin{figure}[H]..
  \centering
  \subcaptionbox{\tiny{\textbf{ Clasificación}}}{\includegraphics[width=1.5in]{img/expect_3.png}}\hspace{1em}%
  \subcaptionbox{\tiny{\textbf{Detección de objetos}}}{\includegraphics[width=1.5in]{img/expect_2.png}}
  \subcaptionbox{\tiny{\textbf{ZSD}}}{\includegraphics[width=1.5in]{img/expect_1.png}}
  \caption{Este es jemplo de las tareas mencionadas. En la escala de los verdes se encuentran las clases vistas \{Caballo, Árbol\}, y en rojo las clases invisibles \{Perro, Persona, Campera, Pantalón, Correa\}}.\
  \label{fig:DetectoresYSZD}
\end{figure}

Existen otros problemas que no mencionamos acá, como la segmentación. Ya que en este documento trataremos la tarea de ZSD. En el capitulo \autoref{cap:trabajo_relacionado} formalizaremos lo aquí explicado.

\section{Estado del arte}
ZSD es un problema que tomo impulso recién en los últimos años, aunque sus estudios se remontan desde mucho antes, como ya mencionamos. Existen muchas técnicas y propuestas para poder resolver este problema, cuando se empezó a leer sobre este tema a fines del 2018 la mas utilizada era usando Multi-modales. Esta es una tecnica que se esta usando mucho como \cite{aytar2017see} quien utilizó imágenes, texto y sonido para generar representaciones discriminatorias profundas que se comparten en las tres modalidades. Del mismo modo, \cite{zhang2017discriminative} utilizó imágenes y descripciones de texto para una mejor localización de la entidad visual basada en el lenguaje natural. La idea (para resolver el problema de ZSD) es utilizar un espacio compartido ente las representaciones de visión y lenguaje.	Para lograr esto se utiliza por un lado \textbf{Las Incrustaciones de palabras}, asignan palabras a una representación vectorial continua codificando similitud semántica entre palabras. Estos vectores de palabras funcionan bien en tareas tales como medir similitudes semánticas y sintácticas entre palabras. Entre los modelos mas famosos se encuentran Glove\cite{pennington-etal-2014-glove} y Word2vec\cite{mikolov2013efficient}. Por otro lado se tiene que poder extraer los \textbf{vectores con representaciones visuales}, entre los mejores modelos se encuentran VGG \cite{simonyan2014very} ResNet \cite{resnet}, Inception \cite{Szegedy_2015_CVPR}. Todos estos modelos usan redes profundas para extraer dichas características.  Como se muestra en la \autoref{fig:EjemploZSD} se utiliza la combinación de representación de palabras y las visuales para inferir un objetos nunca antes vistos por el modelo.\\

\begin{figure}[]
	\centering
	\includegraphics[width=0.8\textwidth]{img/Modelo.jpg}
	\caption{Se describe la tarea de detección de objetos por disparo cero, donde los objetos ``Auto'' y ``Caballo'' se observan  durante el entrenamiento y ``Persona'', ``Perro'' y ``Moto'' son clases invisibles. El enfoque localiza estas clases invisibles aprovechando las relaciones semánticas entre las clases visibles e invisibles y su aspecto visual.}
	\label{fig:EjemploZSD}
\end{figure}

A fines del 2018 se encontro tres trabajos paralelos que apuntaban a resolver el problema de ZSD. \cite{rahman2018zero} \cite{zhu2018zero} \cite{bansal2018zero}. Luego de leer los todos, por una decision personal y con ayuda de mi director eligimos atacar el problema basándonos en el Paper de Bansal \cite{bansal2018zero}. Asi tambien sacamos muchos conceptos sobre disparo cero generalizado de \cite{zero-shot-generalizado}. En Zero-Shot Object Detection\cite{bansal2018zero}, enfrentan el problema de disparo cero de manera similar a la que tenemos los humanos de reconocer un objeto que nunca antes hemos visto, dada una descripción semántica, podemos imaginar el aspecto del objeto.  Es decir, asociamos tanto la palabra que representa el objeto como su aspecto visual. Se utiliza dos extractores para simular estas cualidades, uno semántico y otro visual. Luego, en el momento del entrenamiento se proporcionan ejemplos visuales para solo algunas clases, pero durante la prueba se espera que el modelo reconozca instancias de clases que no se vieron, con la restricción de que las nuevas clases estén semánticamente relacionadas con las clases de entrenamiento.\\



\section{Motivación}

Hoy en día, hay una gran cantidad de modelos, capaces de detectar objetos en una imagen, como son las redes YOLO o Faster R-CNN. Estos, como otros no mencionados, poseen una excelente performance. Pero tienen una gran limitación, necesitan una gran cantidad de imágenes anotadas, para cada clase que se quiere detectar. Conseguir un gran numero de anotaciones, pude resultar un gran desafió, ya se por la naturaliza del problema o por los grandes costo que esto conlleva.\\ 

ZSD es una habilidad que los humanos ya tienen. De hecho, podemos aprender muchas cosas con solo un ``conjunto de datos mínimo". Por ejemplo, tendemos a diferenciar  variedades de la misma fruta o frutas de aspecto similar, aun si hemos visto muy pocas veces cada tipo de fruta. La situación es diferente para las máquinas. Necesitan muchas imágenes para aprender a adaptarse a la variación que se produce de forma natural en lo humanos. Esta habilidad proviene de nuestra base de conocimientos lingüísticos existente, que proporciona una descripción de alto nivel de una clase nueva o no vista y establece una conexión entre ella y las clases que ya conocemos.\\

Por unos minutos dejemos llevarnos por la imaginación y supongamos que se quiere crear un programa capas de reconocer todos los objeto en una imagen, pero objetos de cualquier índole, animales, plantas, artículos de limpieza, o cualquier cosa que se te venga a la mente. Seria casi imposible, si es que no lo es, generar un conjunto de datos que contenga una cantidad considerable de imágenes de todos los objetos posible. Esta idea puede sonar muy descabellada, o no, pero no se puede negar su potencial y su gran cantidad de usos como en interpretaciones de escenas, seguridad, etc. A medida que ZSD continúa desarrollándose, se espera ver más aplicaciones, como mejores recomendaciones y soluciones más avanzadas que marcan automáticamente el contenido inadecuado dentro de las redes sociales, como asi también un fuerte desarrollo en el campo de la robótica.
