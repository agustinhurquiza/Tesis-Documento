\chapter{Introducción y Motivación} \label{cap:intro}

\section{Historia} \label{sec:historia}
La detección de objetos es una de las áreas de la visión por computadora que está creciendo más rápidamente. Gracias al aprendizaje profundo, cada año, los nuevos algoritmos/modelos siguen superando a los anteriores. Aunque la visión por computadora recientemente tomó gran importancia (el momento decisivo ocurrió en 2012 cuando AlexNet ganó ImageNet), ciertamente no es un nuevo campo científico.\\

Uno de los artículos más influyentes en Visión Informática fue publicado por dos neurofisiólogos, David Hubel y Torsten Wiesel~\cite{hubel1959receptive}, en 1959. Su publicación, titulada \textit{``Receptive fields of single neurons in the cat’s striate cortex''}, en español ``Campos receptivos de neuronas individuales en la corteza estriada del gato'', describió las propiedades de respuesta central de las neuronas corticales visuales y como la experiencia visual de un gato moldea su arquitectura cortical. Los investigadores establecieron a través de su experimentación (\autoref{fig:ExpermentoHubelTorsten}) que existen neuronas simples y complejas en la corteza visual primaria, y que el procesamiento visual siempre comienza con estructuras simples como los bordes orientados y gradualmente identifica estructuras mas complejas. En la actualidad, este es el principio básico detrás del aprendizaje profundo.\\

\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{img/cat.jpg}
	\caption{Simple explicación del experimento realizado por David Hubel y Torsten Wiesel}
	\label{fig:ExpermentoHubelTorsten}
\end{figure}

Otro echo importante en la historia de la visión por computadora fue en 1957, Russell Kirsch y sus colegas desarrollaron un aparato que permitía transformar imágenes en cuadrículas de números que las máquinas de lenguaje binario podían entender. 

Poco tiempo después, en la década de 1960 fue cuando la IA se convirtió en una disciplina académica y algunos de los investigadores eran extremadamente optimistas sobre el futuro del campo. En este periodo, Seymour Papert, profesor del laboratorio de IA del MIT, decidió lanzar el Proyecto de Verano y resolver, en pocos meses, el problema de la visión artificial. Los estudiantes debían diseñar una plataforma que pudiera realizar automáticamente segmentación de fondo y extraer objetos no superpuestos de imágenes del mundo real. Claro esta que el proyecto no fue un éxito.  Hoy en día, cincuenta años después, todavía no se ha podido resolver la visión por computadora. Sin embargo, ese proyecto fue el nacimiento oficial de esta disciplina como campo científico. 

Los aportes mas influyentes en este campo empezaron a surgir a partir de los años 2000. En 2001 Paul Viola y Michael Jones~\cite{viola2001rapid} presentaron el primer detector de rostros que funcionó en tiempo real. Aunque no se basaba en el aprendizaje profundo, el algoritmo tenía una relación con éste, ya que, al procesar imágenes aprendió qué características podrían ayudar a localizar caras, inspirándose en el experimento de David Hubel y Torsten Wiesel. 

En 2006 comenzó la competencia de Pascal VOC que permitió evaluar el desempeño de diferentes métodos para el reconocimiento de objetos. Mas tarde, en 2010, siguiendo los pasos de Pascal VOC, se inició el concurso de reconocimiento visual a gran escala ImageNet (ILSVRC), cuya tasa de error durante 2010 y 2011, en el desafió de clasificación de imágenes, rondaba el 26\%.  En 2012, un equipo de la Universidad de Toronto ingresó a la competencia con un modelo de red neuronal convolucional (AlexNet)~\cite{krizhevsky2012imagenet} que cambió todo, dado que logró una tasa de error del 16,4\%. En los años siguientes, las tasas de error en la clasificación de imágenes en ILSVRC cayeron a un pequeño porcentaje, como se observa en la \autoref{fig:EvolucionILSVRC} y los ganadores, desde 2012, siempre han sido redes neuronales convolucionales.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{img/imgnet-grafico.png}
	\caption{Evolución de los modelos propuestos en la competencia ILSVRC}
	\label{fig:EvolucionILSVRC}
\end{figure}

\section{Detectores y ZSD} \label{sec:detectoresyzsd}
La detección de objetos es un subproblema de la visión artificial, que estudia cómo detectar la presencia de objetos en una imagen. Debido a la complejidad de poder detectar todas las instancias de todos los posibles objectos en una imagen, se dividió en distintas tareas para disminuir la dificultad. 

Par explicar los distintos problemas, es necesario distinguir dos conjuntos. Por un lado, los datos de entrenamiento, que consta de las imágenes que se usan para entrenar el modelo con sus respectivas etiquetas, es decir, que objetos se encuentran en la imagen, localización de los objetos, descripción de la imagen, o cualquier información extra que requiera la tarea. Por otro lado, las imágenes de prueba, que es el conjunto donde se observará o medirá la eficiencia del modelo ya entrenado. 

Supongamos que las etiquetas solo cuenta con dos tipos de información, que clase de objeto es, es decir si es un perro, auto, persona, etc. y su localización en la imagen. A todas las clases de objetos que aparecen en los datos de entrenamiento las llamaremos clases visibles o vistas, y todas aquellas clase que no sea una clase vista las llamearemos invisible o no vista. Dicho esto, los distintos problemas son:

\begin{itemize}
	\item \textbf{Clasificación}: consta de un modelo capás de predecir si una clase específica esta presente en una imagen. 
	\item \textbf{Clasificación mas localización}: además de poder clasificar tiene que ser capas de ubicar el objecto en la imagen.
	\item \textbf{Reconocimiento de imagen}: predice que objetos perteneciente a las clases visibles están presente en la imagen. 
	\item \textbf{La detección de objetos}: además de reconocer objetos visibles, tiene que ser capás de localizar dichos objetos. 
	\item \textbf{Reconocimiento por disparo cero}: tiene que poder reconocer clases vistas y no vistas.
	\item \textbf{Detección de objetos por disparo cero} (\textbf{ZSD} por sus siglas en inglés): debe localizar y clasificar todas las instancias de objetos en la imagen, sin depender si es una clase vista o no.
\end{itemize}

\begin{figure}[]
  \centering
  \subcaptionbox{\tiny{\textbf{ Clasificación}}}{\includegraphics[width=1.5in]{img/expect_3.png}}\hspace{1em}%
  \subcaptionbox{\tiny{\textbf{Detección de objetos}}}{\includegraphics[width=1.5in]{img/expect_2.png}}
  \subcaptionbox{\tiny{\textbf{ZSD}}}{\includegraphics[width=1.5in]{img/expect_1.png}}
  \caption{Ejemplo de tareas de clasificación mas localización, detección de objetos y ZSD. En la escala de los verdes se encuentran las clases vistas \{Caballo, Árbol\}, y en rojo las clases invisibles \{Perro, Persona, Campera, Pantalón, Correa\}.}
  \label{fig:DetectoresYSZD}
\end{figure}

La \autoref{fig:DetectoresYSZD} muestra un ejemplo de las distintas tareas  mencionadas anteriormente.\\

Además de los problemas mencionados anteriormente, existen otros como la segmentación, que no desarrollaremos en este trabajo. Aquí, solo nos enfocaremos en ZSD y sus problemas asociados.
 
Existen muchas técnicas propuestas para resolver ZSD. Cuando se empezó a leer sobre este tema a fines del 2018, la mas utilizada consistía en emplear multimodales. Puntualmente existían tres trabajos en paralelos \cite{rahman2018zero}\cite{zhu2018zero}\cite{bansal2018zero} con una metodología similar. La idea de esta técnica es utilizar un espacio compartido ente las representaciones de visión y del lenguaje. Para lograr esto, se utiliza  \textbf{incrustaciones de palabras} y \textbf{vectores con representaciones visuales}. Las primeras asignan a palabras una representación vectorial continua. Estos vectores se utilizan para medir similitudes semánticas y sintácticas entre palabras. Entre los modelos mas famosos se encuentran Glove~\cite{pennington-etal-2014-glove} y Word2vec~\cite{mikolov2013efficient}. Por otro lado, para obtener los vectores visuales de una imagen se utilizan redes profundas. Entre los mejores modelos se encuentran VGG~\cite{simonyan2014very}, ResNet~\cite{resnet} e Inception~\cite{Szegedy_2015_CVPR}. La \autoref{fig:EjemploZSD} describe como se utiliza la combinación de vectores de palabras y visuales para inferir un objetos nunca antes vistos por el modelo.\\

\begin{figure}[]
	\centering
	\includegraphics[width=1\textwidth]{img/Modelo.png}
	\caption{Descripción de la tarea de detección de objetos por disparo cero utilizando multimodales, donde los objetos ``Auto'', ``Camión'', ``Perro'' y ``Tigre'' se observan  durante el entrenamiento,  ``Gato'' y ``Camioneta'' son clases invisibles. El enfoque localiza estas clases no vistas aprovechando las relaciones del espacio semantico.}
	\label{fig:EjemploZSD}
\end{figure}

\section{Motivación} \label{sec:motivacion}

Hoy en día, hay una gran cantidad de modelos, capaces de detectar objetos en una imagen, como son las redes YOLO o Faster R-CNN. Estos, como otros no mencionados, poseen una excelente rendimiento, pero tienen una gran limitación, necesitan una gran cantidad de imágenes anotadas, para cada clase que se quiere detectar. Conseguir un gran numero de anotaciones, pude resultar un gran desafió, ya sea por la naturaliza del problema o por los grandes costo que esto conlleva. Esta dificultad se intenta mitigar con ZSD dado que puede inferir objetos no anotados.\\ 

ZSD es una habilidad que los humanos ya tienen. De hecho, podemos aprender muchas cosas con solo un ``conjunto de datos mínimo". Por ejemplo, tendemos a diferenciar  variedades de la misma fruta o frutas de aspecto similar, aun si hemos visto muy pocas veces cada tipo de fruta. La situación es diferente para las máquinas. Necesitan muchas imágenes para aprender a adaptarse a la variación que se produce de forma natural en lo humanos. Esta habilidad proviene de nuestra base de conocimientos lingüísticos existente, que proporciona una descripción de alto nivel de una clase nueva o no vista y establece una conexión entre ella y las clases que ya conocemos.\\

Por unos minutos dejemos llevarnos por la imaginación y supongamos que se quiere crear un programa capas de reconocer todos los objeto en una imagen, pero objetos de cualquier índole, animales, plantas, artículos de limpieza, o cualquier cosa que se te venga a la mente. Seria casi imposible, si es que no lo es, generar un conjunto de datos que contenga una cantidad considerable de imágenes de todos los objetos posible. Esta idea puede sonar muy descabellada, o no, pero no se puede negar su potencial y su gran cantidad de usos como en interpretaciones de escenas, seguridad, etc. A medida que ZSD continúa desarrollándose, se espera ver más aplicaciones, como mejores recomendaciones y soluciones más avanzadas que marcan automáticamente el contenido inadecuado dentro de las redes sociales, como así también un fuerte desarrollo en el campo de la robótica.

\section{Estructura de la tesis} \label{sec:estructuradelatesis}

Esta tesis se estructura de la siguiente manera. En el~\autoref{cap:preliminares} se detallan los conceptos fundamentales utilizado a lo largo del trabajo. En el~\autoref{cap:metodologia} se comienza formalizando el problema de ZSD y se define la arquitectura empleada para resolverlo. Ademas se describe los conjuntos de datos utilizados para entrenar y medir el rendimiento del modelo, como así también los detalles de nuestra implementación. Por ultimo se define las distintas métricas utilizadas y describe los distintos experimentos realizados. Luego en el~\autoref{cap:analisideresultado} se analizan los resultados obtenidos y se compara con distintos trabajos. Por ultimo el~\autoref{cap:conclusiones} se escriben las conclusiones que se obtuvieron los aportes realizados por esta tesis, los trabajos futuros y mejoras.
