\chapter{Introducción y Motivación} \label{cap:intro}

\section{Introducción} \label{sec:introduccion}
La detección de objetos es un campo de la visión por computadora que estudia cómo detectar la presencia de objetos en una imagen. Esta es una de las áreas de visión por computadora de mayor crecimiento en los últimos años. Si bien es un problema conocido y estudiado desde hace tiempo, recién en la ultima década sus modelos se volvieron mas complejos y eficaces, debido a la aparición de técnicas  de ``Deep Learning''. Sin embargo estos modelos tienen un gran inconveniente, necesitan de un conjunto excesivamente grande de datos anotados para su entrenamiento. Conseguir un gran numero de anotaciones, pude resultar un gran desafió, ya sea por la naturaliza del problema o por los grandes costo que esto conlleva. A esto se le suma la complejidad del problema en si, es decir, poder detectar todas las instancias de todos los posibles objetos en una imagen. Esto motivo a la aparición de métodos como ZSD, que intenten mitigar estas dificultades reduciendo el numero de anotaciones necesarias para entrenar un modelo.\\

Existen Con el objetivo de entender mejor la detección de objetos sin ejemplo, comparemos esta tarea con otras mas conocidas como la clasificación o el aprendizaje sin ejemplos. Antes de explayar los distintos problemas de la visión por computadora, es necesario distinguir dos conjuntos. Por un lado, los datos de entrenamiento, que consta de las imágenes que se usan para entrenar el modelo con sus respectivas etiquetas, es decir, que objetos se encuentran en la imagen, localización de los objetos, descripción de la imagen, o cualquier información extra que requiera la tarea. Por otro lado, las imágenes de prueba, que es el conjunto donde se observará o medirá la eficiencia del modelo ya entrenado. 

Supongamos que las etiquetas solo cuenta con dos tipos de información, que clase de objeto es, es decir si es un perro, auto, persona, etc. y su localización en la imagen. A todas las clases de objetos que aparecen en los datos de entrenamiento las llamaremos clases visibles o vistas, y todas aquellas clase que no sea una clase vista las llamearemos invisible o no vista. Dicho esto, los distintos problemas son:

\begin{itemize}
	\item \textbf{Clasificación}: consta de un modelo capás de predecir si una clase específica esta presente en una imagen. Para su entrenamiento solo es necesario anotar que objeto esta en la imagen.
	\item \textbf{Clasificación más localización}: además de poder clasificar tiene que ser capas de ubicar el objeto en la imagen. Los datos anotados tienen que contar con la clase del objeto y su localización.
	\item \textbf{Reconocimiento de imagen}: predice que objetos perteneciente a las clases visibles están presente en la imagen. Es necesario imágenes de entrenamiento con múltiples objetos presentes.
	\item \textbf{La detección de objetos}: además de reconocer objetos visibles, tiene que ser capás de localizar dichos objetos. Para su entrenamiento se tiene que agregar la localización de todos los objetos. 
	\item \textbf{Aprendizaje sin ejemplos}: ZSL por sus siglas en ingles \textit{Zero-shot learning}, tiene que poder reconocer clases vistas y no vistas. Esta tarea no necesita datos extras al reconocimiento de imagen tradicional. 
	\item \textbf{Detección de objetos sin ejemplos}: ZSD por sus siglas en ingles \textit{Zero-shot object detection}, debe localizar y clasificar todas las instancias de objetos en la imagen, sin depender si es una clase vista o no. Necesita los mismo datos que la detección de objeto, pero no es necesario que todas las clase estén presente en el entrenamiento.
\end{itemize}

La \autoref{fig:DetectoresYSZD} muestra un ejemplo de los resultados esperados por las distintas tareas.\\

\begin{figure}[]
	\centering
	\subcaptionbox{\tiny{\textbf{Clasificación + localización}}}{\includegraphics[width=1.6in]{img/expect_3.png}}
	\subcaptionbox{\tiny{\textbf{Detección de objetos}}}{\includegraphics[width=1.6in]{img/expect_2.png}}
	\subcaptionbox{\tiny{\textbf{ZSD}}}{\includegraphics[width=1.6in]{img/expect_1.png}}
	\caption{Ejemplo de tareas de clasificación más localización (a), detección de objetos (b) y ZSD (c). En la escala de los verdes se encuentran las clases vistas \{Caballo, Árbol\}, y en rojo las clases invisibles \{Perro, Persona, Campera, Pantalón, Correa\}.}
	\label{fig:DetectoresYSZD}
\end{figure}


\section{Historia} \label{sec:historia}

Para entender de donde surge la detección de objetos sin ejemplo, es necesario repasar los aportes más influyentes en la detección de objetos. 

En 2001, Paul Viola y Michael Jones~\cite{viola2001rapid} presentaron el primer detector de rostros que funcionó en tiempo real. Aunque no se basaba en el aprendizaje profundo, el algoritmo tenía una relación con éste, ya que, al procesar imágenes aprendió qué características podrían ayudar a localizar caras, inspirándose en un experimento de dos neurofisiólogos David Hubel y Torsten Wiesel del 1995~\cite{hubel1959receptive}, el cual es la base de la detección actual.

\begin{figure}[]
	\centering
	\begin{subfigure}{0.75\textwidth}
		\centering
		\includegraphics[width=1\textwidth]{img/evolucion_2.png}
		\caption{Las mejoras de precisión en la detección de objetos en los conjuntos de datos VOC07 y COCO. Los detectores en esta figura son: DPM-v1~\cite{felzenszwalb2008discriminatively}, DPM-v5~\cite{sadeghi201430hz}, RCNN~\cite{girshick2014rich}, SPPNet~\cite{girshick2014rich}, Fast RCNN~\cite{he2015spatial}, Faster RCNN~\cite{ren2015faster}, SSD~\cite{liu2016ssd}, FPN~\cite{lin2017feature}, Retina-Net~\cite{lin2017focal}, RefineDet~\cite{zhang2018single}, TridentNet~\cite{li2019scale} y YOLO V4~\cite{wang2020scaled}.}
	\end{subfigure}
	\centering
	\begin{subfigure}{0.75\textwidth}
		\centering
		\includegraphics[width=1\textwidth]{img/evolucion_1.png}
		\caption{El creciente número de publicaciones sobre detección de objetos entre 2000 y 2020 (datos de la búsqueda avanzada de Google academico: allintitle: ``object detection'' OR ``detecting objects'').}
	\end{subfigure}
	\caption{Estadísticas sobre la tarea de detección objetos. Estas imágenes están basadas en gráficos presentados en el trabajo~\cite{zou2019object}.}
	\label{fig:evolucion}
\end{figure}

En 2006, comenzó la competencia de Pascal VOC que permitió evaluar el desempeño de diferentes métodos para el reconocimiento de objetos. Más tarde en 2010, siguiendo los pasos de Pascal VOC, se inició el concurso de reconocimiento visual a gran escala ImageNet (ILSVRC) cuya tasa de error durante 2010 y 2011, en el desafío de clasificación de imágenes, rondaba el 26\%.  En 2012, un equipo de la Universidad de Toronto ingresó a la competencia con un modelo de red neuronal convolucional (AlexNet)~\cite{krizhevsky2012imagenet} que cambió todo, dado que logró una tasa de error del 16,4\%. Este suceso hizo que la tasa de error en clasificación disminuyera pero también impulso a que problemas como la detección de objeto empezaran a utilizar este tipo de red y mejoraran considerablemente. En la \autoref{fig:evolucion} se muestra algunas estadísticas sobre detección de objeto y como este suceso influyo sobre estas.

Todos estos modelos y competencias ayudaron a mejorando el rendimiento de la detección de objetos, pero a su ves empezaron a surgir limitaciones con los datos que se necesitan para entrenar los modelos. Por este motivo la comunidad científica empezó a analizar formas de mitigar estos problemas, dando nacimiento a la detección de objetos sin ejemplos.


\section{Motivación} \label{sec:motivacion}

Por unos minutos dejemos llevarnos por la imaginación y supongamos que se quiere crear un programa capas de reconocer todos los objeto en una imagen, pero objetos de cualquier índole, animales, plantas, artículos de limpieza, o cualquier cosa que se te venga a la mente. Seria casi imposible, si es que no lo es, generar un conjunto de datos que contenga una cantidad considerable de imágenes de todos los objetos posible. Esta idea de detectar todos los tipos de objetos puede sonar muy descabellada, pero no se puede negar su potencial y su gran cantidad de usos como en interpretaciones de escenas, seguridad, robótica, etc. En la actualidad se esta experimentando con modelos de ZSD en robots para interiores~\cite{abdalwhab2019zero} y comenzando a investigar su aplicación en áreas como medicina y conducción autónoma~\cite{rezaei2020zero}. Pero a medida que ZSD continúa desarrollándose, se espera ver más aplicaciones, como mejores recomendaciones y soluciones más avanzadas que marcan automáticamente el contenido inadecuado dentro de las redes sociales, como así también un fuerte desarrollo en el campo de la robótica y conducción autónoma.


\section{Estructura de la tesis} \label{sec:estructuradelatesis}

Esta tesis se estructura de la siguiente manera. En el~\autoref{cap:marcoteorico} se detallan los conceptos fundamentales utilizado a lo largo del trabajo y se formaliza el problema de ZSD. En el~\autoref{cap:arquitecturayconjuntosdedatos} se define la arquitectura empleada para resolver este problema. Además, se describe los conjuntos de datos utilizados para entrenar y medir el rendimiento del modelo, como así también las métricas utilizadas. En el~\autoref{cap:experimentos} se describen los distintos experimentos realizados y se analizan los resultados obtenidos, los cuales se comparan con distintos trabajos. Por ultimo, en el~\autoref{cap:conclusiones} expone las conclusiones que se obtuvieron, los aportes realizados por esta tesis, y los trabajos futuros o mejoras.
